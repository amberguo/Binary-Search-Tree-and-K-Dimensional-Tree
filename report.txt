/**
 * Name: Yingshan Guo
 * Email: yig152@ucsd.edu
 * Reference: Piazza
 * Date: 4/13/2019
 */

[cs100sp19de@ieng6-240]:BST:449$ ./benchmark_bst
Insert benchmarking for BSA and BST:
Number of data to insert: 200
Average time taken to insert for BSA: 827678 milliseconds
Average time taken to insert for BST: 110490 milliseconds

Find benchmarking for BSA and BST:
Number of data in BSA/BST: 200
Number of data to find: 200
Average time taken to find for BSA: 449607 milliseconds
Average time taken to find for BST: 46850 milliseconds


[cs100sp19de@ieng6-240]:BST:451$ ./benchmark_bst
Insert benchmarking for BSA and BST:
Number of data to insert: 4000
Average time taken to insert for BSA: 20853006 milliseconds
Average time taken to insert for BST: 3038698 milliseconds

Find benchmarking for BSA and BST:
Number of data in BSA/BST: 4000
Number of data to find: 4000
Average time taken to find for BSA: 13054756 milliseconds
Average time taken to find for BST: 1223813 milliseconds


[cs100sp19de@ieng6-240]:BST:452$ ./benchmark_bst
Insert benchmarking for BSA and BST:
Number of data to insert: 30000
Average time taken to insert for BSA: 159299368 milliseconds
Average time taken to insert for BST: 22795642 milliseconds

Find benchmarking for BSA and BST:
Number of data in BSA/BST: 30000
Number of data to find: 30000
Average time taken to find for BSA: 118473729 milliseconds
Average time taken to find for BST: 11368952 milliseconds



1.Which data structure was faster for insert()?
 From the above data, we can find that BST is faster in insert()


2.Which data structure was faster for find()?
 From the above data, we can find that BSA is faster in insert()


3. Was there a significant difference that can be explained by the 
differences between the two data structures?
 For insert() and find() in BST and BSA, the time complexities are O(logn).
The difference between time, however, is caused by constant multiplier, not by
growth rate. 
 But this requires BST to be relatively balanced, which means if BST is heavily
skewed, the time complexity of insert and find would be O(n).

Insert benchmarking for BSA and BST:
Number of data to insert: 3000
Average time taken to insert for BSA: 16668680 milliseconds
Average time taken to insert for BST: 92469802 milliseconds

Find benchmarking for BSA and BST:
Number of data in BSA/BST: 3000
Number of data to find: 3000
Average time taken to find for BSA: 12268470 milliseconds
Average time taken to find for BST: 16867883 milliseconds

For this set of data, I used the non-random data instead (0,1,2,3,...), to 
insert and find in the BSA and BST.
As we can see, the efficiency of BST now is outperformed by BSA, due to the fact
that the BST is no longer balanced.


4. How does the validation error change when K goes from 5 to 30? (5, 10, 15 
... 30) Make sure you include the specific output messages in your answer.

  K: 5, Validation Error: 0.095
  K: 10, Validation Error: 0.102
  K: 15, Validation Error: 0.108
  K: 20, Validation Error: 0.109
  K: 30, Validation Error: 0.13
The validation error rises slowly.

5. Based on the information above, find the value of k such that the validation 
error is lowest. 

  when K = 1, the error is lowest.
  K: 1, Validation Error: 0.082



6. Run the program, then paste the printed result into the file. How much does 
the KD tree outperform the Brute Force approach?

Training data size: 10000; Test data size: 10000; Dimension size: 2; K: 1; 
Time taken for KD tree to find KNN: 1193215062 milliseconds
Training data size: 10000; Test data size: 10000; Dimension size: 2; K: 1; 
Time taken for brute force approach to find KNN: 450065654543 milliseconds


7. Do some research on the limitation of KD Tree, and try to find the values 
of 4 constants above such that KD Tree is slower than Brute Force KNN. You must 
include the printed messages in your answer. Your NUM_TRA and NUM_TEST should 
be at least 10000 in order to give reasonable results (small size input does 
not really show the difference).



8. Play with values of 4 constants and show one additional finding with your 
detailed explanation (you should first expect what the result is before playing 
with specific values).
Training data size: 2; Test data size: 2; Dimension size: 5; K: 1; Time taken 
for KD tree to find KNN: 65940 milliseconds
Training data size: 2; Test data size: 2; Dimension size: 5; K: 1; Time taken 
for brute force approach to find KNN: 55965 milliseconds

For extremely small data size, the BruteForce way is more efficient than KDT.

Training data size: 2; Test data size: 2; Dimension size: 100; K: 1; Time taken 
for KD tree to find KNN: 198372 milliseconds
Training data size: 2; Test data size: 2; Dimension size: 100; K: 1; Time taken
for brute force approach to find KNN: 185073 milliseconds

When dimension size increases, the KDT is less efficient than BruteForce.

The reason behind the scene is that when data size is small, we need more time
in KDT to construct the tree and then find KNN. Rather in BruteForce, we only
traverse the array and find KNN, which saves us time of building the tree
structure.

As the dimension size increases, the limitation of KDT is shown. In that 
situation, the search radius (threshold) is likely to intersect a lot of 
hypercubes (because we have a large dimension), which we need to check lots of 
points to get the KNN.



